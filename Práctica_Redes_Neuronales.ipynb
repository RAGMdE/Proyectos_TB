{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/RAGMdE/Proyectos_TB/blob/main/Pr%C3%A1ctica_Redes_Neuronales.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFlbt3gbon-f"
   },
   "source": [
    "# **Clasificación de dígitos con Redes Neuronales**\n",
    "\n",
    "\n",
    "\n",
    "La base de datos MNIST es una gran base de datos de dígitos manuscritos que se utiliza comúnmente para la capacitación de varios sistemas de procesamiento de imágenes y las pruebas en el campo del aprendizaje automático.\n",
    "\n",
    "![MNIST](https://camo.githubusercontent.com/d440ac2eee1cb3ea33340a2c5f6f15a0878e9275/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)\n",
    "\n",
    "\n",
    "\n",
    "Cada imagen tiene 28 x 28 píxeles cuadrados (784 píxeles en total). Se utiliza una división estándar del conjunto de datos para evaluar y comparar modelos, en la que se utilizan 60.000 imágenes para formar un modelo y un conjunto separado de 10.000 imágenes para probarlo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_aOIVIzpoiE"
   },
   "source": [
    "**Carga de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWnIJb0CqiG1"
   },
   "source": [
    "La variable X contiene las matrices de los pixeles de los dígitos, mientras que la variable y contiene las etiquetas correspondientes a cada dígito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gw-jczKfpnul",
    "outputId": "df1450f2-1f16-4982-dce2-6df985668e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n",
      "11501568/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yudOvotZlaeS",
    "outputId": "9e1fd2fb-4aaa-4845-eee1-c71a594c0f13"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mno3w09Ip39Q",
    "outputId": "52e6aec0-45a2-4489-b53a-096438bad251"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1flLirOfp5fn",
    "outputId": "0942c415-465c-4615-ef81-31d1d9ff55ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dX71rEhjqwYD"
   },
   "source": [
    "Vamos a visualizar la primera imagen del conjunto de entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "uTBgxPgHq26z",
    "outputId": "83b64ba1-1566-43a0-ba22-fb4c2c1566f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X_train[0], 'gray')\n",
    "print(\"Digit class:\", y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0AmAiCm12mB"
   },
   "source": [
    "Utiliza esta celda para dibujar algún otro dígito del conjunto de entrenamiento junto con su etiqueta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "EctIk_XXrA4j",
    "outputId": "a8836928-e3f1-474b-d2ca-0ad935fa6d00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit class: 9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Introduce tu código\n",
    "plt.imshow(X_train[19], 'gray')\n",
    "print(\"Digit class:\", y_train[19])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUnDJE6hrXls"
   },
   "source": [
    "Antes de construir modelos de redes neuronales vamos a normalizar los datos. Al ser una imagen en escala de grises, basta por dividir entre 255 para que todos los valores estén comprendidos en el intervalo [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "w58cUbs5rIor"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GY1t72eT-wVI",
    "outputId": "55c8ccac-d54c-4f5c-af86-ff3a796d8790"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hyhQ8pB17E4"
   },
   "source": [
    "Realiza la misma operación con el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "827v7wA5rk6-"
   },
   "outputs": [],
   "source": [
    "# Introduce tu código\n",
    "X_test =X_test.astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hn2JzLVr3L8"
   },
   "source": [
    "Para la variable de salida, tenemos que codificarla con el método 'one hot encoding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZgXDpt0zrtxe"
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "Y_train = np_utils.to_categorical(y_train, 10) # We have 10 classes to codify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8u0sMeUjrodm",
    "outputId": "699ac987-9257-4604-ec6d-6a3c350a9835"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5, 0, 4, ..., 5, 6, 8], dtype=uint8),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.]], dtype=float32))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WpW79o0H1-IW"
   },
   "source": [
    "Realiza la misma operación con el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "wy-QRtElsLeI"
   },
   "outputs": [],
   "source": [
    "# Introduce tu código\n",
    "Y_test = np_utils.to_categorical(y_test, 10) # We have 10 classes to codify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZ7kB-tTseKf"
   },
   "source": [
    "## 1. Red neuronal de una capa\n",
    "Utilizamos una red secuencial, en la que cada capa es seguida de otra en formato de cadena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Xos8xLLjswKV"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpJtYisk2BZV"
   },
   "source": [
    "Creamos la capa, especificando el número de entradas y salidas de la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "j4ckTxIpsyfu"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense\n",
    "denselayer = Dense(10, input_shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vjcmgzR2DDK"
   },
   "source": [
    "Añadimos la capa a la red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "B_bAWMDN2ErZ"
   },
   "outputs": [],
   "source": [
    "model.add(denselayer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rx0cVSnU2Giy"
   },
   "source": [
    "Añadimos la función de activación softmax a la salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sPh8We0Yvk93"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Activation\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rz7OenvL2IyP"
   },
   "source": [
    "La definición de la red está completa. Podemos ver una descripción de la misma con el siguiente comando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rokoHCFEvrY7",
    "outputId": "b17bf6d1-b70f-4abd-bad3-657d7f0fd042"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iESDmObV2Kx_"
   },
   "source": [
    "Tras definir la arquitectura el siguiente paso es compilar la red. Para este paso, hay que especificar la función de error (usaremos 'categorical crossentropy'), el método de optimización (usaremos 'stochastic gradient descent'), y la métrica de desempeño que queremos observar al finalizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "sVnRHoQTwRIO"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQMkXvVV2YyX"
   },
   "source": [
    "A continuación vamos a entrenar la red. Para ello, debemos transformar las matrices de píxeles en vectores, para que puedan utilizarse como entrada en la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "lWKKS0Gt2PWg"
   },
   "outputs": [],
   "source": [
    "trainvectors = X_train.reshape(60000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0C3r8f_02seW"
   },
   "source": [
    "Comprobamos que nuestro conjunto de entrenamiento tiene 784 columnas (características) y 60000 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0elLMjzi2pso",
    "outputId": "53bdc5b8-610e-4838-ebfb-c3e994ea35f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainvectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsjyC0513BeJ"
   },
   "source": [
    "Realiza la misma operación en el conjunto de test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "x6-uR9wr238o"
   },
   "outputs": [],
   "source": [
    "# Inserta tu código\n",
    "testvectors = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CH9nATJ73LOK"
   },
   "source": [
    "Entrenamos la red con el comando **fit**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhlyPCjd3KdU",
    "outputId": "9e0f99e8-46bc-490e-e8a0-64075034d27a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 1s - loss: 1.2913 - accuracy: 0.6960 - 1s/epoch - 3ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 1s - loss: 0.7140 - accuracy: 0.8426 - 889ms/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 1s - loss: 0.5854 - accuracy: 0.8600 - 867ms/epoch - 2ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 1s - loss: 0.5239 - accuracy: 0.8695 - 861ms/epoch - 2ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 1s - loss: 0.4865 - accuracy: 0.8763 - 798ms/epoch - 2ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 1s - loss: 0.4608 - accuracy: 0.8811 - 860ms/epoch - 2ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 1s - loss: 0.4417 - accuracy: 0.8841 - 860ms/epoch - 2ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 1s - loss: 0.4269 - accuracy: 0.8869 - 857ms/epoch - 2ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 1s - loss: 0.4149 - accuracy: 0.8893 - 892ms/epoch - 2ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 1s - loss: 0.4050 - accuracy: 0.8912 - 898ms/epoch - 2ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 1s - loss: 0.3966 - accuracy: 0.8932 - 833ms/epoch - 2ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 1s - loss: 0.3894 - accuracy: 0.8946 - 823ms/epoch - 2ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 1s - loss: 0.3831 - accuracy: 0.8957 - 872ms/epoch - 2ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 1s - loss: 0.3775 - accuracy: 0.8973 - 879ms/epoch - 2ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 1s - loss: 0.3725 - accuracy: 0.8983 - 859ms/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 1s - loss: 0.3680 - accuracy: 0.8993 - 870ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 1s - loss: 0.3639 - accuracy: 0.9000 - 854ms/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 1s - loss: 0.3602 - accuracy: 0.9011 - 853ms/epoch - 2ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 1s - loss: 0.3568 - accuracy: 0.9019 - 862ms/epoch - 2ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 1s - loss: 0.3537 - accuracy: 0.9027 - 863ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5a45af9410>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vFEwJOi9gqJc"
   },
   "source": [
    "Una vez entrenada, obtenemos las predicciones para el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "GuuPINaU4j6P"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = np.argmax(model.predict(testvectors), axis=-1)\n",
    "# preds = model.predict_classes(testvectors) [deprecated]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1HWUg2RhkuF"
   },
   "source": [
    "Comprobamos, para un ejemplo, si la predicción coincide con la realidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "SfMdD0B7gvPB",
    "outputId": "0fce5259-393f-4f11-df0a-2bb20c2b0637"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class 7 predicted class 7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], 'gray')\n",
    "print(\"Real class\", y_test[0], \"predicted class\", preds[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrKRkmgFm355"
   },
   "source": [
    "Veamos ejemplos en los que el modelo ha fallado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "L32l2spBm3Sv",
    "outputId": "c69565bb-ae21-459c-8fab-ac23e18a96ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real class 3 predicted class 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "(fails,) = np.where(y_test != preds)\n",
    "idx = 3\n",
    "plt.imshow(X_test[fails[idx]], 'gray')\n",
    "print(\"Real class\", y_test[fails[idx]], \"predicted class\", preds[fails[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aeaa0uf4nNCy"
   },
   "source": [
    "Medimos la precisión del clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WE5CLCrCnMew",
    "outputId": "524c798a-f78f-4efa-bd9c-53c8b8a4a3a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 1ms/step - loss: 0.3356 - accuracy: 0.9070\n",
      "Test loss 0.335574209690094\n",
      "Test accuracy 0.9070000052452087\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T7FnTUzWn9VK"
   },
   "source": [
    "## 2. Red Neuronal de varias capas (Multilayer Perceptron)\n",
    "Añadimos capas a nuestra red neuronal, con función de activación de tipo sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MvX0uqhYoIPU",
    "outputId": "0bfc64b5-ad93-403b-f9d0-e9983e66b091"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 10)                7850      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,960\n",
      "Trainable params: 7,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(10, input_shape=(784,)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xY8iAvmBoiTT"
   },
   "source": [
    "Compilamos y entrenamos la nueva red, evaluando el nuevo desempeño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgoniE9dokeO",
    "outputId": "6d2bf7b7-b4a5-4486-e505-9d6162998024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 1s - loss: 2.2029 - accuracy: 0.3169 - 1s/epoch - 3ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 1s - loss: 1.9524 - accuracy: 0.5970 - 945ms/epoch - 2ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 1s - loss: 1.7504 - accuracy: 0.6692 - 991ms/epoch - 2ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 1s - loss: 1.5733 - accuracy: 0.7068 - 897ms/epoch - 2ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 1s - loss: 1.4204 - accuracy: 0.7294 - 911ms/epoch - 2ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 1s - loss: 1.2905 - accuracy: 0.7454 - 1s/epoch - 3ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 1s - loss: 1.1812 - accuracy: 0.7590 - 895ms/epoch - 2ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 1s - loss: 1.0892 - accuracy: 0.7712 - 925ms/epoch - 2ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 1s - loss: 1.0118 - accuracy: 0.7822 - 911ms/epoch - 2ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 1s - loss: 0.9463 - accuracy: 0.7947 - 915ms/epoch - 2ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 1s - loss: 0.8905 - accuracy: 0.8047 - 881ms/epoch - 2ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 1s - loss: 0.8425 - accuracy: 0.8145 - 879ms/epoch - 2ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 1s - loss: 0.8009 - accuracy: 0.8238 - 897ms/epoch - 2ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 1s - loss: 0.7645 - accuracy: 0.8310 - 921ms/epoch - 2ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 1s - loss: 0.7325 - accuracy: 0.8375 - 892ms/epoch - 2ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 1s - loss: 0.7040 - accuracy: 0.8425 - 864ms/epoch - 2ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 1s - loss: 0.6787 - accuracy: 0.8480 - 848ms/epoch - 2ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 1s - loss: 0.6559 - accuracy: 0.8521 - 855ms/epoch - 2ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 1s - loss: 0.6353 - accuracy: 0.8558 - 857ms/epoch - 2ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 1s - loss: 0.6166 - accuracy: 0.8589 - 850ms/epoch - 2ms/step\n",
      "313/313 [==============================] - 1s 1ms/step - loss: 0.5927 - accuracy: 0.8673\n",
      "Test loss 0.5927422642707825\n",
      "Test accuracy 0.8672999739646912\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Me6tP1hIpZkv"
   },
   "source": [
    "Para mejorar el desempeño de la red, vamos a incrementar el número de neuronas en las capas ocultas, utilizar la función de activación ReLU y modificar el algoritmo de optimización por *adam* (mejora del algoritmo de gradiente descendente)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "ds55lyyqora-"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34VRqA4cp9Vg",
    "outputId": "804f7cad-5670-464f-9c98-23c0bc1934c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 2s - loss: 0.3802 - accuracy: 0.8952 - 2s/epoch - 4ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 2s - loss: 0.1781 - accuracy: 0.9492 - 2s/epoch - 3ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 1s - loss: 0.1294 - accuracy: 0.9633 - 1s/epoch - 3ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 2s - loss: 0.1028 - accuracy: 0.9702 - 2s/epoch - 3ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 2s - loss: 0.0843 - accuracy: 0.9757 - 2s/epoch - 3ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 2s - loss: 0.0706 - accuracy: 0.9800 - 2s/epoch - 3ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 2s - loss: 0.0598 - accuracy: 0.9834 - 2s/epoch - 3ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 2s - loss: 0.0523 - accuracy: 0.9848 - 2s/epoch - 3ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 2s - loss: 0.0451 - accuracy: 0.9876 - 2s/epoch - 3ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 2s - loss: 0.0399 - accuracy: 0.9891 - 2s/epoch - 3ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 2s - loss: 0.0347 - accuracy: 0.9905 - 2s/epoch - 3ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 2s - loss: 0.0305 - accuracy: 0.9915 - 2s/epoch - 3ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 2s - loss: 0.0261 - accuracy: 0.9931 - 2s/epoch - 3ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 2s - loss: 0.0222 - accuracy: 0.9945 - 2s/epoch - 3ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 2s - loss: 0.0202 - accuracy: 0.9949 - 2s/epoch - 3ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 2s - loss: 0.0185 - accuracy: 0.9953 - 2s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 2s - loss: 0.0161 - accuracy: 0.9962 - 2s/epoch - 3ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 2s - loss: 0.0133 - accuracy: 0.9972 - 2s/epoch - 3ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 2s - loss: 0.0117 - accuracy: 0.9975 - 2s/epoch - 3ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 2s - loss: 0.0110 - accuracy: 0.9975 - 2s/epoch - 3ms/step\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0816 - accuracy: 0.9788\n",
      "Test loss 0.08157924562692642\n",
      "Test accuracy 0.9787999987602234\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUz5iGwgqGhh"
   },
   "source": [
    "Define una nueva red con dos capas ocultas, cada una con 512 neuronas y una función de activación ReLU. Para la salida, utiliza la función de activación *softmax*. Utiliza *adam* como algoritmo de optimización y compara el desempeño de esta nueva red con los resultados anteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "65b5VIVsp-GC"
   },
   "outputs": [],
   "source": [
    "# Introduce tu código\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1sZSDwN9DP2d",
    "outputId": "8146c36e-3277-4048-f093-4a131b0bcdb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 6s - loss: 0.2151 - accuracy: 0.9372 - 6s/epoch - 13ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 6s - loss: 0.0786 - accuracy: 0.9758 - 6s/epoch - 13ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 6s - loss: 0.0513 - accuracy: 0.9832 - 6s/epoch - 13ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 6s - loss: 0.0357 - accuracy: 0.9887 - 6s/epoch - 12ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 6s - loss: 0.0274 - accuracy: 0.9907 - 6s/epoch - 13ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 7s - loss: 0.0209 - accuracy: 0.9927 - 7s/epoch - 14ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 6s - loss: 0.0169 - accuracy: 0.9941 - 6s/epoch - 12ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 6s - loss: 0.0161 - accuracy: 0.9944 - 6s/epoch - 13ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 6s - loss: 0.0154 - accuracy: 0.9949 - 6s/epoch - 13ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 6s - loss: 0.0143 - accuracy: 0.9951 - 6s/epoch - 13ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 6s - loss: 0.0110 - accuracy: 0.9964 - 6s/epoch - 13ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 6s - loss: 0.0107 - accuracy: 0.9964 - 6s/epoch - 13ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 6s - loss: 0.0081 - accuracy: 0.9973 - 6s/epoch - 12ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 6s - loss: 0.0103 - accuracy: 0.9965 - 6s/epoch - 13ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 6s - loss: 0.0106 - accuracy: 0.9968 - 6s/epoch - 13ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 6s - loss: 0.0090 - accuracy: 0.9970 - 6s/epoch - 12ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 6s - loss: 0.0126 - accuracy: 0.9960 - 6s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 6s - loss: 0.0077 - accuracy: 0.9976 - 6s/epoch - 12ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 6s - loss: 0.0029 - accuracy: 0.9991 - 6s/epoch - 13ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 6s - loss: 0.0057 - accuracy: 0.9983 - 6s/epoch - 12ms/step\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1165 - accuracy: 0.9789\n",
      "Test loss 0.11651035398244858\n",
      "Test accuracy 0.9789000153541565\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5Qs26nqqcpT"
   },
   "source": [
    "A continuación, vamos a introducir regularización con el método **dropout**. En este ejemplo, creamos una capa dropout, que recibe las salidas de la capa anterior y las asigna a 0 con una probabilidad del 30%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Kkwk7KCquvr",
    "outputId": "91fc905c-dca4-4fa6-f1d1-6e7befa171ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 4s - loss: 0.2973 - accuracy: 0.9148 - 4s/epoch - 9ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 4s - loss: 0.1314 - accuracy: 0.9611 - 4s/epoch - 8ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 4s - loss: 0.0918 - accuracy: 0.9728 - 4s/epoch - 8ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 4s - loss: 0.0722 - accuracy: 0.9779 - 4s/epoch - 8ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 4s - loss: 0.0586 - accuracy: 0.9819 - 4s/epoch - 8ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 4s - loss: 0.0487 - accuracy: 0.9848 - 4s/epoch - 8ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 4s - loss: 0.0413 - accuracy: 0.9873 - 4s/epoch - 8ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 4s - loss: 0.0352 - accuracy: 0.9888 - 4s/epoch - 8ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 4s - loss: 0.0298 - accuracy: 0.9912 - 4s/epoch - 8ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 4s - loss: 0.0281 - accuracy: 0.9912 - 4s/epoch - 8ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 4s - loss: 0.0239 - accuracy: 0.9925 - 4s/epoch - 8ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 4s - loss: 0.0225 - accuracy: 0.9930 - 4s/epoch - 8ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 4s - loss: 0.0195 - accuracy: 0.9936 - 4s/epoch - 8ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 4s - loss: 0.0185 - accuracy: 0.9938 - 4s/epoch - 8ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 4s - loss: 0.0165 - accuracy: 0.9948 - 4s/epoch - 8ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 4s - loss: 0.0137 - accuracy: 0.9957 - 4s/epoch - 8ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 4s - loss: 0.0155 - accuracy: 0.9945 - 4s/epoch - 8ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 4s - loss: 0.0141 - accuracy: 0.9955 - 4s/epoch - 8ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 4s - loss: 0.0128 - accuracy: 0.9958 - 4s/epoch - 8ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 4s - loss: 0.0120 - accuracy: 0.9956 - 4s/epoch - 8ms/step\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0661 - accuracy: 0.9827\n",
      "Test loss 0.06614263355731964\n",
      "Test accuracy 0.982699990272522\n"
     ]
    }
   ],
   "source": [
    "from keras.layers.core import Dropout\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    trainvectors, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testvectors, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cJ3fpNOn1fU4"
   },
   "source": [
    "## 3. Redes Neuronales Convolucionales\n",
    "Para mejorar el desempeño del clasificador de imágenes, necesitamos redes que consideren los datos de entrada como imágenes, y tengan en cuenta la relación entre los píxeles. Las redes convolutivas son la mejor manera de hacer esto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mb_LYVPn1zvv"
   },
   "source": [
    "Para las redes convolucionales, necesitamos organizar los datos en forma de tensores, con las siguientes dimensiones:  \n",
    "- Índice de la imagen (por ejemplo, la 3ª imagen del dataset)\n",
    "- Índice de la fila\n",
    "- Índice de la columna\n",
    "- Índice del canal RGB\n",
    "\n",
    "En nuestro caso, tenemos imágenes en blanco y negro de 28 filas x 28 columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "Q5A_bOyH1hoK"
   },
   "outputs": [],
   "source": [
    "traintensor = X_train.reshape(60000, 28, 28, 1)\n",
    "testtensor = X_test.reshape(10000, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9E4Ku3D2Tol"
   },
   "source": [
    "Cuando definimos una red convolucional, las capas de convolución y pooling trabajan conjuntamente. La manera más habitual de utilizar estas capas es siguiendo el siguiente patrón:\n",
    "- Una capa convolucional con función de activación ReLU\n",
    "- Una capa pooling\n",
    "- Dropout (si queremos introducir regularización)\n",
    "\n",
    "Definimos por tanto nuestra red:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "Vn3dcxz72SVD"
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 1))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrPlnbbY20mO"
   },
   "source": [
    "Tras las capas convolucionales+pooling, tenemos que transformar el tensor a un vector, de manera que la salida final de la red sea el número de clases (en nuestro caso 10). Para ello creamos una capa de tipo **Flatten**, seguida de una capa de tipo **Dense**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "2aJ1V9Dm2xXI"
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Flatten\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CAe8UwXn3GbI"
   },
   "source": [
    "A continuación, compilamos y entrenamos nuestra red convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EFxQ1OFX3Enz",
    "outputId": "882386db-7c72-4bdc-aa32-08efb758973a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 23s - loss: 0.3653 - accuracy: 0.9000 - 23s/epoch - 48ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 22s - loss: 0.1410 - accuracy: 0.9598 - 22s/epoch - 48ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 22s - loss: 0.1049 - accuracy: 0.9694 - 22s/epoch - 48ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 22s - loss: 0.0878 - accuracy: 0.9742 - 22s/epoch - 47ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 22s - loss: 0.0780 - accuracy: 0.9767 - 22s/epoch - 47ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 22s - loss: 0.0702 - accuracy: 0.9791 - 22s/epoch - 48ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 22s - loss: 0.0652 - accuracy: 0.9807 - 22s/epoch - 48ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 23s - loss: 0.0606 - accuracy: 0.9818 - 23s/epoch - 48ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 23s - loss: 0.0560 - accuracy: 0.9830 - 23s/epoch - 49ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 22s - loss: 0.0538 - accuracy: 0.9832 - 22s/epoch - 48ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 22s - loss: 0.0507 - accuracy: 0.9845 - 22s/epoch - 47ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 22s - loss: 0.0479 - accuracy: 0.9851 - 22s/epoch - 47ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 22s - loss: 0.0441 - accuracy: 0.9865 - 22s/epoch - 48ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 22s - loss: 0.0438 - accuracy: 0.9866 - 22s/epoch - 47ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 23s - loss: 0.0412 - accuracy: 0.9873 - 23s/epoch - 48ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 22s - loss: 0.0379 - accuracy: 0.9882 - 22s/epoch - 47ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 22s - loss: 0.0370 - accuracy: 0.9883 - 22s/epoch - 47ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 22s - loss: 0.0364 - accuracy: 0.9880 - 22s/epoch - 47ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 22s - loss: 0.0348 - accuracy: 0.9887 - 22s/epoch - 47ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 22s - loss: 0.0317 - accuracy: 0.9900 - 22s/epoch - 47ms/step\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.0466 - accuracy: 0.9848\n",
      "Test loss 0.04657972976565361\n",
      "Test accuracy 0.9847999811172485\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "btCUnllU33Vt"
   },
   "source": [
    "Construye y entrena una CNN con las siguientes capas:\n",
    "- Dos capas convolucionales con 32 kernels de tamaño 3x3 y función ReLU\n",
    "- Una Capa MaxPooling de tamaño 2\n",
    "- Un 25% de DropOout\n",
    "- Una capa de tipo Flatten\n",
    "- Una capa densa con 128 neuronas y función ReLU\n",
    "- Un 50% de dropout\n",
    "- Una capa de salida densa con función de activación softmax\n",
    "\n",
    "¿Hay mejora en el desempeño?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "x1SLr_E_3KrJ"
   },
   "outputs": [],
   "source": [
    "# Introduce tu código\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "kernel_size = 3 # Size of the kernel for the convolution layers\n",
    "pool_size = 2 # Size of the pooling region for the pooling layers\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 1))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(32, # Number convolution channels to generate\n",
    "                        (kernel_size, kernel_size), # Size of convolution kernels\n",
    "                        padding='valid', # Strategy to deal with borders\n",
    "                        input_shape=(img_rows, img_cols, 1))) # Size = image rows x image columns x channels\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(pool_size, pool_size)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZ-4vZ5cI8Cu",
    "outputId": "c0b02dbc-d6b9-4da4-ef9f-02c81e2a26c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 - 91s - loss: 1.0141 - accuracy: 0.5674 - 91s/epoch - 193ms/step\n",
      "Epoch 2/20\n",
      "469/469 - 90s - loss: 0.8956 - accuracy: 0.5906 - 90s/epoch - 192ms/step\n",
      "Epoch 3/20\n",
      "469/469 - 89s - loss: 0.8787 - accuracy: 0.5944 - 89s/epoch - 191ms/step\n",
      "Epoch 4/20\n",
      "469/469 - 90s - loss: 0.8685 - accuracy: 0.5954 - 90s/epoch - 191ms/step\n",
      "Epoch 5/20\n",
      "469/469 - 89s - loss: 0.8587 - accuracy: 0.5988 - 89s/epoch - 190ms/step\n",
      "Epoch 6/20\n",
      "469/469 - 90s - loss: 0.8583 - accuracy: 0.5972 - 90s/epoch - 191ms/step\n",
      "Epoch 7/20\n",
      "469/469 - 89s - loss: 0.8554 - accuracy: 0.6004 - 89s/epoch - 190ms/step\n",
      "Epoch 8/20\n",
      "469/469 - 89s - loss: 0.8533 - accuracy: 0.5984 - 89s/epoch - 191ms/step\n",
      "Epoch 9/20\n",
      "469/469 - 89s - loss: 0.8529 - accuracy: 0.5962 - 89s/epoch - 191ms/step\n",
      "Epoch 10/20\n",
      "469/469 - 89s - loss: 0.8453 - accuracy: 0.6005 - 89s/epoch - 191ms/step\n",
      "Epoch 11/20\n",
      "469/469 - 90s - loss: 0.8444 - accuracy: 0.5991 - 90s/epoch - 191ms/step\n",
      "Epoch 12/20\n",
      "469/469 - 90s - loss: 0.8500 - accuracy: 0.5985 - 90s/epoch - 191ms/step\n",
      "Epoch 13/20\n",
      "469/469 - 89s - loss: 0.8441 - accuracy: 0.6001 - 89s/epoch - 191ms/step\n",
      "Epoch 14/20\n",
      "469/469 - 89s - loss: 0.8411 - accuracy: 0.6015 - 89s/epoch - 189ms/step\n",
      "Epoch 15/20\n",
      "469/469 - 89s - loss: 0.8459 - accuracy: 0.5980 - 89s/epoch - 189ms/step\n",
      "Epoch 16/20\n",
      "469/469 - 89s - loss: 0.8407 - accuracy: 0.6004 - 89s/epoch - 190ms/step\n",
      "Epoch 17/20\n",
      "469/469 - 89s - loss: 0.8403 - accuracy: 0.5996 - 89s/epoch - 190ms/step\n",
      "Epoch 18/20\n",
      "469/469 - 89s - loss: 0.8389 - accuracy: 0.6008 - 89s/epoch - 189ms/step\n",
      "Epoch 19/20\n",
      "469/469 - 90s - loss: 0.8398 - accuracy: 0.6003 - 90s/epoch - 191ms/step\n",
      "Epoch 20/20\n",
      "469/469 - 90s - loss: 0.8341 - accuracy: 0.6040 - 90s/epoch - 193ms/step\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.0311 - accuracy: 0.9918\n",
      "Test loss 0.031123435124754906\n",
      "Test accuracy 0.9918000102043152\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=2 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n5gc2Dge4mBW"
   },
   "source": [
    "Por último, probamos la arquitectura **[LeNet](http://yann.lecun.com/exdb/lenet/)**, cuya efectividad ha sido demostrada en este caso particular. Las capas que utiliza son las siguientes: \n",
    "- Capa convolucional con 20 kernels de tamaño 5 y función ReLU\n",
    "- MaxPooling de tamaño 2 y stride 2\n",
    "- 25% Dropout\n",
    "- Capa convolucional con 50 kernels de tamaño 5 y función ReLU\n",
    "- MaxPooling de tamaño 2 y stride 2\n",
    "- 25% Dropout\n",
    "- Capa Flatten\n",
    "- Capa Densa con 500 neuronas y función ReLU\n",
    "- 50% Dropout\n",
    "- Capa Densa con función softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zb34AACG4_zM",
    "outputId": "c462f77f-da89-4011-e07c-58ea70abc5b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 49s 103ms/step - loss: 0.2733 - accuracy: 0.9123\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.0796 - accuracy: 0.9753\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.0602 - accuracy: 0.9811\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.0502 - accuracy: 0.9846\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 48s 101ms/step - loss: 0.0423 - accuracy: 0.9871\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 48s 102ms/step - loss: 0.0376 - accuracy: 0.9879\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0345 - accuracy: 0.9889\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0312 - accuracy: 0.9903\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0289 - accuracy: 0.9906\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 47s 101ms/step - loss: 0.0275 - accuracy: 0.9915\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0266 - accuracy: 0.9912\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 47s 99ms/step - loss: 0.0218 - accuracy: 0.9933\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0220 - accuracy: 0.9930\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0193 - accuracy: 0.9937\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0212 - accuracy: 0.9932\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0197 - accuracy: 0.9938\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0184 - accuracy: 0.9940\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 46s 99ms/step - loss: 0.0182 - accuracy: 0.9944\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 47s 100ms/step - loss: 0.0162 - accuracy: 0.9945\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.0194 - accuracy: 0.9945\n",
      "Test loss 0.019410390406847\n",
      "Test accuracy 0.9944999814033508\n"
     ]
    }
   ],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(20, (5, 5),\n",
    "                        padding='valid',\n",
    "                        input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Convolution2D(50, (5, 5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    traintensor, # Training data\n",
    "    Y_train, # Labels of training data\n",
    "    batch_size=128, # Batch size for the optimizer algorithm\n",
    "    epochs=20, # Number of epochs to run the optimizer algorithm\n",
    "    verbose=1 # Level of verbosity of the log messages\n",
    ")\n",
    "score = model.evaluate(testtensor, Y_test)\n",
    "print(\"Test loss\", score[0])\n",
    "print(\"Test accuracy\", score[1])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "BZ7kB-tTseKf",
    "T7FnTUzWn9VK",
    "cJ3fpNOn1fU4"
   ],
   "include_colab_link": true,
   "name": "Práctica Redes Neuronales",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
